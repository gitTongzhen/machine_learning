class torch.nn.Linear（in_features，out_features，bias = True ）

对传入数据应用线性变换：y = A x+ b

 
参数：

in_features - 每个输入样本的大小

out_features - 每个输出样本的大小

bias - 如果设置为False，则图层不会学习附加偏差。默认值：True

torch.nn.Relu()

实现relu激活函数的功能


pytorch中torch.nn.dropout和torch.nn.F.dropout区别

所以这里其实就根据个人喜好来使用nn.dropout或者F.dropout，有一些观点认为nn.dropout更好，理由如下：

Dropout被设计为只在训练中使用，所以当你对模型进行预测或评估时，你需要关闭Dropout。nn.dropout可以方便地处理这个问题，在模型进入eval时立即关闭Dropout，而F.dropout并care你是什么模式。
分配给模型的所有模块都在模型中注册。所以模型类跟踪它们，这就是为什么可以通过调用eval()关闭dropout模块。当使用F.dropout时，您的模型并不知道它，所以模型的summary中也不会出现dropout模块


