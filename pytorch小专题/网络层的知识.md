class torch.nn.Linear（in_features，out_features，bias = True ）

对传入数据应用线性变换：y = A x+ b

 
参数：

in_features - 每个输入样本的大小

out_features - 每个输出样本的大小

bias - 如果设置为False，则图层不会学习附加偏差。默认值：True

torch.nn.Relu()

实现relu激活函数的功能


pytorch中torch.nn.dropout和torch.nn.F.dropout区别

所以这里其实就根据个人喜好来使用nn.dropout或者F.dropout，有一些观点认为nn.dropout更好，理由如下：

Dropout被设计为只在训练中使用，所以当你对模型进行预测或评估时，你需要关闭Dropout。nn.dropout可以方便地处理这个问题，在模型进入eval时立即关闭Dropout，而F.dropout并care你是什么模式。
分配给模型的所有模块都在模型中注册。所以模型类跟踪它们，这就是为什么可以通过调用eval()关闭dropout模块。当使用F.dropout时，您的模型并不知道它，所以模型的summary中也不会出现dropout模块


Variable（变量）
autograd.Variable 是包的核心类. 它包装了张量, 并且支持几乎所有的操作. 一旦你完成了你的计算, 你就可以调用 .backward() 方法, 然后所有的梯度计算会自动进行.

你还可以通过 .data 属性来访问原始的张量, 而关于该 variable（变量）的梯度会被累计到 .grad上去.

#unsqueeze:扩充数据维度，在0起的指定位置N加上维数为1的维度
#squeeze:   维度压缩，在0起的指定位置N，去掉维数为1的的维度

torch.unsqueeze()这个函数主要是对数据维度进行扩充。给指定位置加上维数为一的维度，比如原本有个三行的数据（3），在0的位置加了一维就变成一行三列（1,3）。a.squeeze(N) 就是在a中指定位置N加上一个维数为1的维度。还有一种形式就是b=torch.squeeze(a，N) a就是在a中指定位置N加上一个维数为1的维度

torch.squeeze() 这个函数主要对数据的维度进行压缩，去掉维数为1的的维度，比如是一行或者一列这种，一个一行三列（1,3）的数去掉第一个维数为一的维度之后就变成（3）行。squeeze(a)就是将a中所有为1的维度删掉。不为1的维度没有影响。a.squeeze(N) 就是去掉a中指定的维数为一的维度。还有一种形式就是b=torch.squeeze(a，N) a中去掉指定的定的维数为一的维度
```
import torch
import matplotlib.pyplot as plt
 
 
a=torch.randn(2,3)#标准正态分布生成随机数
print(a)
print(a.shape) #torch.Size([2, 3])
 
 
#unsqueeze:扩充数据维度，在0起的指定位置N加上维数为一的维度
b=torch.unsqueeze(a,1) #[2, 3]中在位置1，就是=3的位置增加维度1，3向后串
print(b.shape)#torch.Size([2, 1, 3])
 
c=torch.unsqueeze(a,0) #[2, 3]中在位置0，就是=1的位置增加维度1，2向后串
print(c.shape)#torch.Size([1, 2, 3])
#--------------------------------------------------------------#
f=torch.randn(3)
print(f)
print(f.shape)#torch.Size([3])
g=f.unsqueeze(0) #[3]中在位置0，就是=3的位置增加维度1，3向后串
print(g.shape)#torch.Size([1, 3])
#--------------------------------------------------------------#
#squeeze:维度压缩，在0起的指定位置，去掉维数为1的的维度
d=torch.squeeze(c) # d=c.squeeze(0)
print(d)
print(d.shape)#torch.Size([2, 
```
Conv2d 的知识
```
import torch
# x[batch_size,channels,height_1,width_1]
# conv[channels,output,height,width]
# 输出 [2,8,7-2+1,3-3+1]
x = torch.randn(2,1,7,3)
print(type(x))
conv = torch.nn.Conv2d(1,8,(2,3))
 torch.nn
res = conv(x)

print(res.shape)
```
